{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Start_Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/hw2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Start_Time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 308\u001b[0m\n\u001b[1;32m    303\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 308\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[13], line 295\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m preparedxFeat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepared_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# noSource1 = remove_source1_data(xFeat)\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# # Save the cleaned DataFrame to a new CSV file\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# noSource1.to_csv('noSource1.csv', index=False)\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m#preparedxFeat = prepare_data(xFeat)\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m preparedxFeat \u001b[38;5;241m=\u001b[39m extract_features(preparedxFeat)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m#preparedxFeat.to_csv('prepared_data.csv', index=False)\u001b[39;00m\n\u001b[1;32m    299\u001b[0m corrM \u001b[38;5;241m=\u001b[39m cal_corr(preparedxFeat)\n",
      "Cell \u001b[0;32mIn[13], line 90\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(df):\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Extract day of the week as a categorical feature\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart_Time\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     91\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart_Time\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_day_of_week\u001b[39m(day_of_week):\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Start_Time'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def remove_missing_data(df):\n",
    "    \"\"\"\n",
    "    Remove rows with missing data for any of the columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame without rows containing missing data\n",
    "    \"\"\"\n",
    "\n",
    "    # NEED TO DROP EVERY SAMPLE FROM SOURCE1 AS THESE HAVE INACCURATE START/END TIMES\n",
    "    cleaned_df = df.dropna()\n",
    "    return cleaned_df\n",
    "\n",
    "# FEATURES:\n",
    "\n",
    "    # determine the distance in time between when the weather was recorded and the start time of the accident\n",
    "    # REMOVE:\n",
    "        # Start_Lat\n",
    "        # Start_Lng\n",
    "        # End_Lat\n",
    "        # End_Lng\n",
    "        # Distance\n",
    "        # Street\n",
    "        # City\n",
    "        # County\n",
    "        # State\n",
    "        # Country\n",
    "        # Timezone\n",
    "        # Airport_Code\n",
    "        # Weather_Timestamp\n",
    "        # Turning Loop\n",
    "    # ONE HOT ENCODE:\n",
    "        # Turn all true values into 1 and all false values into 0\n",
    "        # Weather_Condition\n",
    "        # Sunrise_Sunset (Day = 0, Night = 1, Other = 3)\n",
    "        # Civil_Twilight\n",
    "        # Nautical_Twilight\n",
    "        # Astronomical_Twilight\n",
    "\n",
    "# STEP 1\n",
    "def remove_source1_data(df):\n",
    "    cleaned_df = df[df['Source'] != 'Source1']\n",
    "    df = df.drop(columns=['Source'])\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "# STEP 2\n",
    "def prepare_data(df):\n",
    "    # take only releveant features\n",
    "    selected_features = ['Severity', 'Start_Time', 'End_Time', 'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
    "    \n",
    "    # clean this data by removing missing data\n",
    "    cleaned_data = remove_missing_data(df[selected_features]) \n",
    "\n",
    "    #cleaned_data = cleaned_data.drop_duplicates()\n",
    "\n",
    "    # turn categorical data data into numerical data:\n",
    "    # for Weather_Condition, have six possible values to indicate no special condition (0), rain (1), snow (2), fog (3), rain (4), thunderstorm (5)\n",
    "    cleaned_data = group_weather_conditions(cleaned_data)\n",
    "\n",
    "    # convert values in specific columns\n",
    "    cleaned_data['Sunrise_Sunset'] = cleaned_data['Sunrise_Sunset'].replace({'Day': 0, 'Night': 1})\n",
    "    cleaned_data['Civil_Twilight'] = cleaned_data['Civil_Twilight'].replace({'Day': 0, 'Night': 1})\n",
    "    cleaned_data['Nautical_Twilight'] = cleaned_data['Nautical_Twilight'].replace({'Day': 0, 'Night': 1})\n",
    "    cleaned_data['Astronomical_Twilight'] = cleaned_data['Astronomical_Twilight'].replace({'Day': 0, 'Night': 1})\n",
    "\n",
    "    # convert 'false' to 0 and 'true' to 1 in boolean columns\n",
    "    bool_columns = ['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal']\n",
    "    cleaned_data[bool_columns] = cleaned_data[bool_columns].replace({False: 0, True: 1})\n",
    "\n",
    "    cleaned_data = remove_missing_data(cleaned_data) \n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# STEP 3 - extract important features including the target variable (traffic duraction) and others (day of week)\n",
    "def extract_features(df):\n",
    "\n",
    "    # Extract day of the week as a categorical feature\n",
    "    df['day_of_week'] = pd.to_datetime(df['Start_Time'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%A')\n",
    "    df['hour'] = pd.to_datetime(df['Start_Time'], format='%m/%d/%y %H:%M').dt.hour\n",
    "\n",
    "    def get_day_of_week(day_of_week):\n",
    "        if day_of_week == 'Sunday':\n",
    "            return 0\n",
    "        elif day_of_week == 'Monday':\n",
    "            return 1 \n",
    "        elif day_of_week == 'Tuesday':\n",
    "            return 2\n",
    "        elif day_of_week == 'Wednesday':\n",
    "            return 3\n",
    "        elif day_of_week == 'Thursday':\n",
    "            return 4\n",
    "        elif day_of_week == 'Friday':\n",
    "            return 5\n",
    "        elif day_of_week == 'Saturday':\n",
    "            return 6\n",
    "\n",
    "    def get_time_of_day(hour):\n",
    "        if 5 <= hour < 12:\n",
    "            return 0 # morning\n",
    "        elif 12 <= hour < 17:\n",
    "            return 1 # afternoon\n",
    "        elif 17 <= hour < 20:\n",
    "            return 2 # evening\n",
    "        else:\n",
    "            return 3 # night\n",
    "\n",
    "    df['time_of_day'] = df['hour'].apply(get_time_of_day)\n",
    "    df['day_of_week'] = df['day_of_week'].apply(get_day_of_week)\n",
    "\n",
    "    # Extract traffic duration in minutes\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['End_Time'] = pd.to_datetime(df['End_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['Traffic_Duration'] = round((df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60)\n",
    "\n",
    "    df = df.drop(columns=['Start_Time', 'End_Time', 'hour'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def group_weather_conditions(df):\n",
    "    weather_mapping = {\n",
    "        'Light Rain': 1,\n",
    "        'Overcast': 0,\n",
    "        'Mostly Cloudy': 0,\n",
    "        'Rain': 1,\n",
    "        'Light Snow': 2,\n",
    "        'Haze': 3,\n",
    "        'Scattered Clouds': 0,\n",
    "        'Partly Cloudy': 0,\n",
    "        'Clear': 0,\n",
    "        'Snow': 2,\n",
    "        'Light Freezing Drizzle': 1,\n",
    "        'Light Drizzle': 1,\n",
    "        'Fog': 3,\n",
    "        'Shallow Fog': 3,\n",
    "        'Heavy Rain': 1,\n",
    "        'Light Freezing Rain': 1,\n",
    "        'Cloudy': 0,\n",
    "        'Drizzle': 1,\n",
    "        'Light Rain Showers': 1,\n",
    "        'Mist': 1,\n",
    "        'Smoke': 3,\n",
    "        'Patches of Fog': 3,\n",
    "        'Light Freezing Fog': 3,\n",
    "        'Light Haze': 3,\n",
    "        'Light Thunderstorms and Rain': 5,\n",
    "        'Thunderstorms and Rain': 5,\n",
    "        'Fair': 0,\n",
    "        'Volcanic Ash': 3,\n",
    "        'Blowing Sand': 3,\n",
    "        'Blowing Dust / Windy': 3,\n",
    "        'Widespread Dust': 3,\n",
    "        'Fair / Windy': 0,\n",
    "        'Rain Showers': 1,\n",
    "        'Mostly Cloudy / Windy': 0,\n",
    "        'Light Rain / Windy': 1,\n",
    "        'Hail': 4,\n",
    "        'Heavy Drizzle': 1,\n",
    "        'Showers in the Vicinity': 1,\n",
    "        'Thunderstorm': 5,\n",
    "        'Light Rain Shower': 1,\n",
    "        'Light Rain with Thunder': 5,\n",
    "        'Partly Cloudy / Windy': 0,\n",
    "        'Thunder in the Vicinity': 5,\n",
    "        'T-Storm': 5,\n",
    "        'Heavy Thunderstorms and Rain': 5,\n",
    "        'Thunder': 5,\n",
    "        'Heavy T-Storm': 5,\n",
    "        'Funnel Cloud': 5,\n",
    "        'Heavy T-Storm / Windy': 5,\n",
    "        'Blowing Snow': 2,\n",
    "        'Light Thunderstorms and Snow': 5,\n",
    "        'Heavy Snow': 2,\n",
    "        'Low Drifting Snow': 2,\n",
    "        'Light Ice Pellets': 2,\n",
    "        'Ice Pellets': 2,\n",
    "        'Squalls': 5,\n",
    "        'N/A Precipitation': 0,\n",
    "        'Cloudy / Windy': 0,\n",
    "        'Light Fog': 3,\n",
    "        'Sand': 3,\n",
    "        'Snow Grains': 2,\n",
    "        'Snow Showers': 2,\n",
    "        'Heavy Thunderstorms and Snow': 5,\n",
    "        'Rain / Windy': 1,\n",
    "        'Heavy Rain / Windy': 1,\n",
    "        'Heavy Ice Pellets': 2,\n",
    "        'Light Snow / Windy': 2,\n",
    "        'Heavy Freezing Rain': 1,\n",
    "        'Small Hail': 4,\n",
    "        'Heavy Rain Showers': 1,\n",
    "        'Thunder / Windy': 5,\n",
    "        'Drizzle and Fog': 3,\n",
    "        'T-Storm / Windy': 5,\n",
    "        'Blowing Dust': 3,\n",
    "        'Smoke / Windy': 3,\n",
    "        'Haze / Windy': 3,\n",
    "        'Tornado': 5,\n",
    "        'Light Drizzle / Windy': 1,\n",
    "        'Widespread Dust / Windy': 3,\n",
    "        'Wintry Mix': 1,\n",
    "        'Wintry Mix / Windy': 1,\n",
    "        'Light Snow with Thunder': 5,\n",
    "        'Fog / Windy': 3,\n",
    "        'Snow and Thunder': 5,\n",
    "        'Light Snow Shower': 2,\n",
    "        'Sleet': 2,\n",
    "        'Light Snow and Sleet': 2,\n",
    "        'Snow / Windy': 2,\n",
    "        'Rain Shower': 1,\n",
    "        'Snow and Sleet': 2,\n",
    "        'Light Sleet': 2,\n",
    "        'Heavy Snow / Windy': 2,\n",
    "        'Freezing Drizzle': 1,\n",
    "        'Light Freezing Rain / Windy': 1,\n",
    "        'Thunder / Wintry Mix': 5,\n",
    "        'Blowing Snow / Windy': 2,\n",
    "        'Freezing Rain': 1,\n",
    "        'Light Snow and Sleet / Windy': 2,\n",
    "        'Snow and Sleet / Windy': 2,\n",
    "        'Sleet / Windy': 2,\n",
    "        'Heavy Freezing Rain / Windy': 1,\n",
    "        'Squalls / Windy': 5,\n",
    "        'Light Rain Shower / Windy': 1,\n",
    "        'Snow and Thunder / Windy': 5,\n",
    "        'Light Sleet / Windy': 2,\n",
    "        'Sand / Dust Whirlwinds': 3,\n",
    "        'Mist / Windy': 3,\n",
    "        'Drizzle / Windy': 1,\n",
    "        'Duststorm': 3,\n",
    "        'Sand / Dust Whirls Nearby': 3,\n",
    "        'Thunder and Hail': 5,\n",
    "        'Heavy Sleet': 2,\n",
    "        'Freezing Rain / Windy': 1,\n",
    "        'Light Snow Shower / Windy': 2,\n",
    "        'Partial Fog': 3,\n",
    "        'Thunder / Wintry Mix / Windy': 5,\n",
    "        'Patches of Fog / Windy': 3,\n",
    "        'Rain and Sleet': 2,\n",
    "        'Light Snow Grains': 2,\n",
    "        'Partial Fog / Windy': 3,\n",
    "        'Sand / Dust Whirlwinds / Windy': 3,\n",
    "        'Heavy Snow with Thunder': 5,\n",
    "        'Light Snow Showers': 2,\n",
    "        'Heavy Blowing Snow': 2,\n",
    "        'Light Hail': 4,\n",
    "        'Heavy Smoke': 3,\n",
    "        'Heavy Thunderstorms with Small Hail': 5,\n",
    "        'Light Thunderstorm': 5,\n",
    "        'Heavy Freezing Drizzle': 1,\n",
    "        'Light Blowing Snow': 2,\n",
    "        'Thunderstorms and Snow': 5,\n",
    "    }\n",
    "    df['Weather_Condition'] = df['Weather_Condition'].replace(weather_mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def cal_corr(df):\n",
    "    # calculate the correlation matrix and perform the heatmap\n",
    "    corrMat = df.corr(method='pearson')\n",
    "    return corrMat\n",
    "\n",
    "# def select_features(df):\n",
    "#     selected_features = ['hour', 'RH_out', 'RH_8', 'T2', 'lights']\n",
    "#     return df[selected_features]\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main file to run from the command line.\n",
    "    \"\"\"\n",
    "    # set up the program to take in arguments from the command line\n",
    "\n",
    "    # # load the train and test data\n",
    "    preparedxFeat = pd.read_csv('prepared_data.csv')\n",
    "\n",
    "    # noSource1 = remove_source1_data(xFeat)\n",
    "    \n",
    "    # # Save the cleaned DataFrame to a new CSV file\n",
    "    # noSource1.to_csv('noSource1.csv', index=False)\n",
    "\n",
    "    #preparedxFeat = prepare_data(xFeat)\n",
    "\n",
    "    #preparedxFeat = extract_features(preparedxFeat)\n",
    "\n",
    "    #preparedxFeat.to_csv('prepared_data.csv', index=False)\n",
    "\n",
    "    corrM = cal_corr(preparedxFeat)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corrM, annot=False, cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation Matrix Heatmap\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7847dafe490a87d1e60f1f4e05f7ce4ee4d0662652b17f01bc278c00edf7e2cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
